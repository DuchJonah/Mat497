{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DuchJ\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "\n",
    "#function that deletes the object in the index of the array and creates a new array with a copy of that object\n",
    "#this is essentially append for numpy arrays\n",
    "def poprow(my_array,pr):\n",
    "    \"\"\" row popping in numpy arrays\n",
    "    Input: my_array - NumPy array, pr: row index to pop out\n",
    "    Output: [new_array,popped_row] \"\"\"\n",
    "    i = pr\n",
    "    pop = my_array[i]\n",
    "    pop = np.array(pop)\n",
    "\n",
    "    pop = np.array(pop).astype(int)\n",
    "\n",
    "    new_array = np.delete(my_array,i)\n",
    "    return [new_array,pop]\n",
    "\n",
    "#function which deletes the top values in the array to a certain number, \n",
    "#but saves the deleted ones in a separate array using the poprow function\n",
    "#this is to delete the HAZ hardness indents that landed in the FZ, \n",
    "#but we're gonna append the FZ indents to the FZ array later ;)\n",
    "def del_FZ(hardness_array, not_HAZ_number):\n",
    "    \"\"\"input: the hardness array and the number of points we're deleting\n",
    "    output: [the new hardness array, the deleted points or FZ array]\"\"\"\n",
    "    FZ_array = []\n",
    "    FZ_array = np.asarray (FZ_array, dtype=int)\n",
    "    \n",
    "    #not_HAZ_number = int(not_HAZ_number)\n",
    "    #FZ_array = np.empty(shape=not_HAZ_number, dtype=int)\n",
    "\n",
    "    hardness_array_cut = hardness_array\n",
    "\n",
    "    x=0\n",
    "    for x in range(not_HAZ_number):\n",
    "        [hardness_array_cut, FZ_pop] = poprow(hardness_array_cut, 0)\n",
    "        FZ_array = np.append(FZ_array, FZ_pop)\n",
    "\n",
    "    return [hardness_array_cut, FZ_array]\n",
    "\n",
    "#function which cleans up the data from the sheet, renames the columns, and returns the hardness array \n",
    "def trim_fat (hard_sheet):\n",
    "    \"\"\"Input: the excel spreadsheet from pandas, and the number of points that landed in the FZ (int)\n",
    "    Output: the hardness in a numpy array, and the FZ hardness points also in a numpy array\"\"\"\n",
    "    hard_sheet_length = len(hard_sheet.index)\n",
    "    hard_sheet_new = hard_sheet.drop(\n",
    "            [0,1,2,(hard_sheet_length-1),(hard_sheet_length-2),(hard_sheet_length-3)]\n",
    "            )\n",
    "    hard_sheet_new = hard_sheet_new.rename(\n",
    "        columns={\n",
    "            \"\":\"index\",\n",
    "            \"Name\":\"Mean Length\",\n",
    "            \"Number of Included Replicates\":\"Hardness\",\n",
    "        })\n",
    "\n",
    "    hardness_array =  hard_sheet_new.Hardness.to_numpy()\n",
    "    \n",
    "    return hardness_array\n",
    "\n",
    "#this function takes the excel file name, opens the file, trims the data, removes the FZ from the HAZ and appends it to the FZ array\n",
    "def get_hard_740H (filename, not_HAZ_number):\n",
    "    \"\"\"\n",
    "    xlsx = pd.ExcelFile(filename)\n",
    "    hardness_sheets = []\n",
    "    for sheet in xlsx.sheet_names:\n",
    "        hardness_sheets.append(xlsx.parse(sheet))\n",
    "    \"\"\"\n",
    "    \n",
    "    HAZ= pd.read_excel(filename, sheet_name=0)\n",
    "    FZ= pd.read_excel(filename, sheet_name=1)\n",
    "    \n",
    "    HAZ_trim = trim_fat(HAZ)\n",
    "    [HAZ_array, FZ_in_HAZ] = del_FZ(HAZ_trim, not_HAZ_number)\n",
    "    \n",
    "    \n",
    "    FZ_trim = trim_fat(FZ)\n",
    "    FZ_array = np.append(FZ_trim, FZ_in_HAZ)\n",
    "    \n",
    "    return [HAZ_array, FZ_array]\n",
    "\n",
    "def get_hard_347H (filename, meta_data):\n",
    "    #for 347H order is [material, vector_ID, time, time_type, temperature, constant, sheet_order, sample_info]\n",
    "    #sheet_order is ['haz', 'fz', 'bm'] sample_info is a list with \n",
    "    \n",
    "    '''\n",
    "    funtion takes the filename of the excel document and the meta_data as input\n",
    "    output is a list of lists (still trying to figure out best way to do this)\n",
    "    of the order [material, temperature, time, strain, trace ID, hardness vector]\n",
    "    '''\n",
    "    \n",
    "    sheet_number = how_many_sheets_347 (meta_data)\n",
    "    sheet = 0\n",
    "    haz_count = 0\n",
    "    strain_count = 0\n",
    "    \n",
    "    #this is a preliminary storage device, i'm not conviced that a list of lists\n",
    "    #is the best way to store this data, ideally we would run this once and just get\n",
    "    #one document to save and call for the data analysis\n",
    "    hardness_array = []\n",
    "    \n",
    "    #It appears that a dataframe would be the best method to store this data\n",
    "    #we're putting the dataframe into another function because i love functions so much\n",
    "    \n",
    "    for sheet in range(sheet_number):\n",
    "        vector_type = meta_data[6][sheet%3] #this will select haz, fz, or bm\n",
    "        \n",
    "        #want to increase by 1 every three counts\n",
    "        if sheet !=0 and sheet%3 == 0:\n",
    "            strain_count +=3\n",
    "        \n",
    "        if meta_data[1] == 'z' and sheet == 10:\n",
    "            vector_type = 'fz'\n",
    "            \n",
    "            hardness_vector= pd.read_excel(filename, sheet_name=sheet)\n",
    "            trimmed_vector = trim_fat(hardness_vector)\n",
    "            \n",
    "            #then we add FZ to datasheet and break, it's the end of the loop\n",
    "            hardness_array.append(\n",
    "                    [meta_data[0], meta_data[4], meta_data[2], meta_data[3], \n",
    "                     meta_data[7][strain_count], 'FZ', trimmed_vector]\n",
    "                    )\n",
    "            \n",
    "            #return [material, temperature, time, time type, strain, trace ID, hardness vector]\n",
    "            \n",
    "            break\n",
    "        \n",
    "        hardness_vector= pd.read_excel(filename, sheet_name=sheet)\n",
    "        trimmed_vector = trim_fat(hardness_vector)\n",
    "        \n",
    "        if vector_type == 'haz': #0 means a HAZ trace, but... UPDATE CHANGED IT SO 'haz' WORKS\n",
    "            #if there is a problem here, lets look at meta_347 and using += instead of append\n",
    "            not_HAZ_number = int(meta_data[7][1 + haz_count]) #not_HAZ_number is the number of HAZ indents in the FZ\n",
    "            [HAZ_array, FZ_in_HAZ] = del_FZ(trimmed_vector, not_HAZ_number) #run through the function to get the fresh new HAZ array and the FZ array\n",
    "            haz_count +=3 #if sample info is [constant, FZ number, sheet number,...] \n",
    "            #we need to progress 3 spaces to the next FZ number next loop\n",
    "            \n",
    "            hardness_array.append(\n",
    "                    [meta_data[0], meta_data[4], meta_data[2], meta_data[3],\n",
    "                     meta_data[7][strain_count], 'HAZ', HAZ_array]\n",
    "                    )\n",
    "            \n",
    "        elif vector_type == 'fz':\n",
    "            #add the trimmed vector to the FZ in HAZ from the previous loop (look at the paragraph above ya dummy seesh)\n",
    "            FZ_array = np.append(trimmed_vector, FZ_in_HAZ)\n",
    "            #then we add the FZ to the datasheet\n",
    "            \n",
    "            hardness_array.append(\n",
    "                    [meta_data[0], meta_data[4], meta_data[2], meta_data[3], \n",
    "                     meta_data[7][strain_count], 'FZ', FZ_array]\n",
    "                    )\n",
    "            \n",
    "        else: #it is bm otherwise\n",
    "            BM_array = trimmed_vector\n",
    "            hardness_array.append(\n",
    "                    [meta_data[0], meta_data[4], meta_data[2], meta_data[3], \n",
    "                     meta_data[7][strain_count], 'BM', BM_array]\n",
    "                    )\n",
    "           \n",
    "    return hardness_array\n",
    "        \n",
    "        #return [material, temperature, time, strain, trace ID, hardness vector]\n",
    "        # if vector_ID == 'a' sample info is just FZ number\n",
    "        # if vector_ID == 'c' order is [strain, FZ_number, first_vector]\n",
    "\n",
    "#assuming the material is 740H, the filename should have all the meta data\n",
    "def meta_740H(filename):\n",
    "    mlist = re.split(\"( )\",filename)\n",
    "    material = mlist[0]\n",
    "    temperature = int(mlist[2])\n",
    "    strain = int(mlist[6])\n",
    "    FZ_number = 2 * int(mlist[18])\n",
    "    #time= int(mlist[26])\n",
    "    \n",
    "    if mlist[26] == '2k':\n",
    "        time = 2000.0\n",
    "    elif mlist[26] == '4k':\n",
    "        time = 4000.0\n",
    "    elif mlist[26] == '8k':\n",
    "        time = 8000.0\n",
    "    elif mlist[26] == '1k':\n",
    "        time = 1000.0\n",
    "    else:\n",
    "        time = float(mlist[26])\n",
    "    \n",
    "    time_type = (re.split(\"\\\\.\",mlist[-1]))[0]\n",
    "    \n",
    "    return [material, time, time_type, temperature, strain, FZ_number]\n",
    "\n",
    "def meta_347H(filename):\n",
    "    mlist = re.split(\"( )\", filename)\n",
    "    \n",
    "    vector_ID = mlist [0]\n",
    "    if vector_ID == 'a': #this was the standard before c, one sample, one condition etc\n",
    "        material = mlist[2] #its 347H, shouldn't be different\n",
    "        composition = mlist[4] #either 0.08c or 0.04c\n",
    "        temperature = int(mlist[6]) #either 600 or 675\n",
    "        strain = int(mlist[10]) #either 0, 5, 10, 15, or 20 % strain\n",
    "        width = int(mlist[34]) #width of hardness trace\n",
    "        FZ_number = width * int(mlist[22])\n",
    "        time = int(mlist [38])\n",
    "        \n",
    "        if mlist[38] == '2k':\n",
    "            time = 2000.0\n",
    "        elif mlist[38] == '4k':\n",
    "            time = 4000.0\n",
    "        elif mlist[38] == '8k':\n",
    "            time = 8000.0\n",
    "        elif mlist[38] == '1k':\n",
    "            time = 1000.0\n",
    "        \n",
    "        time_type = re.split(\"()\", mlist[40])[2] + re.split(\"()\", mlist[40])[4]\n",
    "        sheet_order = ['haz', 'fz', 'bm']\n",
    "        sample_info = [(1==0), FZ_number]\n",
    "        \n",
    "        constant = ['composition and strain', composition, strain]\n",
    "        \n",
    "        return [material, vector_ID, time, time_type, temperature, constant, \\\n",
    "                sheet_order, sample_info, width]\n",
    "\n",
    "    elif vector_ID == 'b': #meta data 'b' means we have two 0 pct samples in the same sample\n",
    "        material = '347H'\n",
    "        width = 3 #by the time we got to b, c, and z we standarized the width to three indents wide\n",
    "        \n",
    "        time = int(mlist [2])\n",
    "        \n",
    "        if mlist[2] == '2k':\n",
    "            time = 2000.0\n",
    "        elif mlist[2] == '4k':\n",
    "            time = 4000.0\n",
    "        elif mlist[2] == '8k':\n",
    "            time = 8000.0\n",
    "        elif mlist[2] == '1k':\n",
    "            time = 1000.0\n",
    "        \n",
    "        time_type = mlist[4]\n",
    "        strain = 0\n",
    "        temp = re.split(\"()\", mlist[10])\n",
    "        temperature = int(temp[2]+temp[4]+temp[6])\n",
    "        sheet_1 = mlist[14]\n",
    "        sheet_2 = mlist[16]\n",
    "        sheet_3 = mlist[18]\n",
    "        sheet_order = [sheet_1, sheet_2, sheet_3]\n",
    "        \n",
    "        composition_A = mlist[20]\n",
    "        FZ_number_A = 3 * int(re.split(\"()\", mlist[24])[2])\n",
    "        A_first = int(re.split(\"()\", mlist[22])[4])\n",
    "        A_info = [composition_A, FZ_number_A, A_first]\n",
    "        \n",
    "        composition_B = mlist[26]\n",
    "        FZ_number_B = 3 * int(re.split(\"()\", mlist[30])[2])\n",
    "        B_first = int(re.split(\"()\", mlist[28])[4])\n",
    "        B_info = [composition_B, FZ_number_B, B_first]\n",
    "        \n",
    "        sample_info = A_info + B_info #sample info will be a list with info in order\n",
    "        \n",
    "        constant = ['strain', strain]\n",
    "        \n",
    "        return [material, vector_ID, time, time_type, temperature, constant, \\\n",
    "                sheet_order, sample_info, width]\n",
    "        \n",
    "    elif vector_ID == 'c' or 'z': #meta data 'c' means we have all four samples in the same sample, z is a mistake at the end (experimental)\n",
    "        material = '347H'\n",
    "        width = 3 #by the time we got to b, c, and z we standarized the width to three indents wide\n",
    "        #time = int(mlist[2])\n",
    "        \n",
    "        if mlist[2] == '2k':\n",
    "            time = 2000.0\n",
    "        elif mlist[2] == '4k':\n",
    "            time = 4000.0\n",
    "        elif mlist[2] == '8k':\n",
    "            time = 8000.0\n",
    "        else:\n",
    "            time = float(mlist[2])\n",
    "        \n",
    "        time_type = mlist[4]\n",
    "        composition = int(mlist[6])\n",
    "        temp = re.split(\"()\", mlist[10])\n",
    "        temperature = int(temp[2]+temp[4]+temp[6])\n",
    "        constant = ['composition', composition]\n",
    "        \n",
    "        sheet_1 = mlist[14]\n",
    "        sheet_2 = mlist[16]\n",
    "        sheet_3 = mlist[18]\n",
    "        sheet_order = [sheet_1, sheet_2, sheet_3] \n",
    "        #the sheet_order is labels for the types of hardness traces\n",
    "        #for example, the most common one will be: haz, fz, bm\n",
    "        #so far there are no other orders, but this is to make it a bit easier if it changes in the future\n",
    "        \n",
    "        counting = 20\n",
    "        \n",
    "        sample_info = []\n",
    "\n",
    "        #why four? there are four sets of hardness traces (order haz, fz, bm)\n",
    "        #for each set of 3 hardness traces, we will get the strain value, strain\n",
    "        #then we will get the number for the first vector, which sheet is it on?, first_vector\n",
    "        #then we will get FZ number\n",
    "        #if we have a vector ID z, that means that the fourth set is actually just a FZ trace\n",
    "        for x in range (4):\n",
    "            \n",
    "            strain = re.split(\"()\", mlist[counting])[2]+re.split(\"()\", \\\n",
    "                              mlist[counting])[4]\n",
    "            if not strain.isdigit(): #if it is 5pct, strain above will return strain '5p', but 10pct will return '10'\n",
    "                strain = re.split(\"()\", mlist[counting])[2]\n",
    "            strain = int(strain)\n",
    "            \n",
    "            first_vector = re.split(\"()\", mlist[counting+2])[4]+re.split(\"()\", \\\n",
    "                                    mlist[counting+2])[6]\n",
    "            if not first_vector.isdigit(): #if it is not starting with vector 10, this will run\n",
    "                first_vector = re.split(\"()\", mlist[counting+2])[4]\n",
    "            first_vector = int(first_vector)\n",
    "            \n",
    "            if vector_ID=='z' and x==3:\n",
    "                sample_info += [strain, 0, first_vector]\n",
    "                counting += 6\n",
    "            else:\n",
    "                FZ_number = 3 * int(re.split(\"()\", mlist[counting+4])[2])\n",
    "                sample_info += [strain, FZ_number, first_vector]\n",
    "                counting += 6        \n",
    "    else:\n",
    "        print ('you should debug') #this shouldn't happen, so there is a spelling mistake or code error somewhere\n",
    "    \n",
    "    return [material, vector_ID, time, time_type, temperature, constant, \\\n",
    "            sheet_order, sample_info,width]\n",
    "\n",
    "def get_meta(test_file):\n",
    "    if re.split(\"( )\", test_file)[0] == '740H':\n",
    "        meta_data = meta_740H(test_file)\n",
    "    else:\n",
    "        meta_data = meta_347H(test_file)\n",
    "    return meta_data\n",
    "\n",
    "#this function takes the vector ID and returns the number of sheets in the excel file\n",
    "def how_many_sheets_347 (meta_data):\n",
    "    vector_ID = meta_data[1]\n",
    "    sheet_number = 2\n",
    "    if vector_ID == 'a':\n",
    "        sheet_number = 3\n",
    "    elif vector_ID == 'b':\n",
    "        sheet_number = 6\n",
    "    elif vector_ID == 'z':\n",
    "        sheet_number = 10\n",
    "    else:\n",
    "        sheet_number = 12\n",
    "    return sheet_number\n",
    "\n",
    "#this function returns the composition of the 347H (low or high). I messed up, so this is the easiest way\n",
    "#NOTE: this only works for vector ID of a\n",
    "def get_composition (meta_data):\n",
    "    vector_ID = meta_data [1]\n",
    "    \n",
    "    if vector_ID == 'b':\n",
    "        print ('You cannot use get_composition for a b type vector')\n",
    "    else:\n",
    "        composition = meta_data[5][1]\n",
    "        if composition=='0.04c' or composition == 4:\n",
    "            composition_347 = 0.04\n",
    "        elif composition == '0.08c' or composition == 8:\n",
    "            composition_347 = 0.08\n",
    "            \n",
    "        return composition_347\n",
    "\n",
    "#this function will take the get_hard data and meta data and make it into a dataframe!\n",
    "#'''\n",
    "def make_data_frame_347 (hardness_array, meta_data, hardness_data):\n",
    "    \n",
    "    hardness_data = pd.DataFrame(\n",
    "            columns=['Material','Composition','Temperature','Time','Strain',\n",
    "                     'Type','Hardness','Width']\n",
    "                )\n",
    "    \n",
    "    #lets start by getting our metadata again \n",
    "    #[material, vector_ID, time, time_type, temperature, constant, sheet_order, sample_info,width]\n",
    "    vector_ID = meta_data[1]\n",
    "    hardness_width = meta_data[8]\n",
    "    #'''\n",
    "    b_type_count=0\n",
    "    \n",
    "    for i in range(len(hardness_array)):\n",
    "        material = hardness_array[i][0]\n",
    "        \n",
    "        #get the composition, which i kinda screwed up on earlier but this is fine\n",
    "        if vector_ID != 'b':\n",
    "            composition = get_composition(meta_data) \n",
    "            #for a, c, and z types composition is right in the metadata!\n",
    "            strain = int(hardness_array[i][4])\n",
    "            \n",
    "        else: \n",
    "            #otherwise we have to go to the sample_info part of the metadata\n",
    "            composition = meta_data[7][b_type_count]\n",
    "            strain = meta_data[5][1]\n",
    "                    \n",
    "            #[material, vector_ID, time, time_type, temperature, constant, sheet_order, sample_info]\n",
    "            \n",
    "            #sample info is labeled composition_A, FZ_number_A, A_first, composition_b... \n",
    "            #thus we want composition_A for the HAZ, FZ, and BM then after 3 \n",
    "            #go to composition_b. every third file we increment this by 3 to \n",
    "            #get from composition a to b (three spaces)\n",
    "            if i !=0 and i%3 == 0:\n",
    "                b_type_count +=3\n",
    "                \n",
    "        if composition in ('0.04C', '0.04c', '0.4C'):\n",
    "            composition = 0.04\n",
    "        elif composition in ('0.08C', '0.08c', '0.8C'):\n",
    "            composition = 0.08\n",
    "        else:\n",
    "            composition = int(composition)\n",
    "                \n",
    "        temperature = int(hardness_array[i][1])\n",
    "        \n",
    "        if temperature == 670:\n",
    "            temperature = 675\n",
    "        \n",
    "        if hardness_array[i][3]=='hr':\n",
    "            time = float(hardness_array[i][2])\n",
    "        elif hardness_array[i][3] =='min':\n",
    "            time = float(hardness_array[i][2])/60.0\n",
    "            \n",
    "        hardness_type = hardness_array[i][5]        \n",
    "        \n",
    "        hardness = hardness_array[i][6]\n",
    "        \n",
    "        #pd.DataFrame({\"a\":[1, 2, 3, 4], \"b\":[5, 6, 7, 8]})\n",
    "        \n",
    "        hardness_data_2 = pd.DataFrame({\n",
    "            \"Material\":[material],\"Composition\":[composition],\n",
    "            \"Temperature\":[temperature],\"Time\":[time],\"Strain\":[strain],\n",
    "            \"Type\":[hardness_type],\"Hardness\":[hardness], \"Width\":[hardness_width]\n",
    "                })\n",
    "        \n",
    "        hardness_data = hardness_data.append(hardness_data_2, ignore_index = True)\n",
    "    \n",
    "    return hardness_data\n",
    "\n",
    "def make_data_frame_740H (hardness_array, meta_data, hardness_data):\n",
    "   \n",
    "    #[material, time, time_type, temperature, strain, FZ_number]\n",
    "    \n",
    "    HAZ_hardness = hardness_array[0]\n",
    "    FZ_hardness = hardness_array[1]\n",
    "    #meta data order is [material, time, time_type, temperature, strain, FZ_number]\n",
    "    \n",
    "    material = '740H'\n",
    "    temperature = meta_data[3]\n",
    "    if meta_data[1]==0:\n",
    "        hardness_width = 1 #I already averaged all the time 0 samples for the HAZ\n",
    "        #note, this will assign a hardness_width of 1 to the FZ as well, but we're averaging the whole FZ, so don't worry\n",
    "    else:\n",
    "        hardness_width = 2 #assumption is that all 740H traces are 2 indents wide\n",
    "    \n",
    "    #reminder that meta data is [material, time, time_type, temperature, strain, FZ_number]\n",
    "    \n",
    "    if meta_data[2]=='hr':\n",
    "        time = float(meta_data[1])\n",
    "    elif meta_data[2] =='min':\n",
    "        time = float(meta_data[1])/60.0\n",
    "    \n",
    "    strain = meta_data[4]\n",
    "    \n",
    "    for i in range (2):\n",
    "        if i ==0:\n",
    "            hardness_type = 'HAZ'\n",
    "            hardness = HAZ_hardness\n",
    "            \n",
    "        else:\n",
    "            hardness_type = 'FZ'\n",
    "            hardness = FZ_hardness\n",
    "        \n",
    "        hardness_data_2 = pd.DataFrame({\n",
    "                \"Material\":[material],\"Temperature\":[temperature],\n",
    "                \"Time\":[time],\"Strain\":[strain], \"Type\":[hardness_type],\n",
    "                \"Hardness\":[hardness],\"Width\":[hardness_width]\n",
    "                })\n",
    "        \n",
    "        hardness_data = hardness_data.append(hardness_data_2, ignore_index = True)\n",
    "    \n",
    "    return hardness_data\n",
    "\n",
    "#''' Great! Now we have a data frame with all the information from one excel \n",
    "    #file, now lets do it with all the excel files in a directory!\n",
    "def fill_data_frame(path):\n",
    "    \n",
    "    hardness_data = pd.DataFrame(\n",
    "            columns=['Material','Composition','Temperature','Time','Strain',\n",
    "                     'Type','Hardness','Width']\n",
    "                )\n",
    "\n",
    "    files = []\n",
    "    # r=root, d=directories, f = files\n",
    "    for r, d, f in os.walk(path):\n",
    "        for file in f:\n",
    "            if '.xlsx' in file:\n",
    "                files.append(os.path.join(r, file))\n",
    "\n",
    "    for f in files:\n",
    "        \n",
    "        hardness_data_i = pd.DataFrame(\n",
    "            columns=['Material','Composition','Temperature','Time','Strain',\n",
    "                     'Type','Hardness','Width']\n",
    "                )\n",
    "        \n",
    "        f_title= f.split('\\\\')\n",
    "        f_title = f_title[-1]\n",
    "        \n",
    "        #print (f_title)\n",
    "        \n",
    "        #'''\n",
    "        meta_data = get_meta(f_title)\n",
    "        \n",
    "        material_ID = meta_data[0]\n",
    "        \n",
    "        if material_ID == '347H' or material_ID == '347h':\n",
    "            hardness_array = get_hard_347H (f, meta_data)\n",
    "            hardness_data_i = make_data_frame_347 (hardness_array, meta_data, hardness_data_i)\n",
    "        else:\n",
    "            hardness_array = get_hard_740H (f, int(meta_data[5]))\n",
    "            hardness_data_i = make_data_frame_740H (hardness_array, meta_data, hardness_data_i)\n",
    "            \n",
    "        hardness_data = hardness_data.append(hardness_data_i, ignore_index = True)\n",
    "    \n",
    "    hardness_data.to_csv(r'C:\\Users\\DuchJ\\Desktop\\PhD Please\\18. Hardness and Precipiate Modeling\\all_data_width.csv')\n",
    "    #return hardness_data\n",
    "    #'''\n",
    "    \n",
    "\n",
    "'''    \n",
    "#test_file = 'a 347H 0.08c 675 c 20 pct 0 v1 is fz 3 down into fz v1 is 3 wide 100 hr.xlsx'    \n",
    "#test_file= 'b 500 hr 0 pctC 600degc order haz fz bm 0.4C v1to3 2fz 0.8C v4to6 3fz.xlsx'\n",
    "test_file = 'a 347H 0.04c 600 c 5 pct 0 v1 is fz 4 down into fz v1 is 4 wide 100 hr.xlsx'\n",
    "meta_data = get_meta(test_file)\n",
    "hardness_array = get_hard_347H (test_file, meta_data)\n",
    "#hardness_frame = make_data_frame_347(hardness_array, meta_data)\n",
    "'''\n",
    "\n",
    "path = r'C:\\Users\\DuchJ\\Desktop\\PhD Please\\18. Hardness and Precipiate Modeling\\Raw_Hardness\\all_data'\n",
    "\n",
    "hardness_data = fill_data_frame (path)\n",
    "\n",
    "#eventually we want to pickle this bb\n",
    "#df.to_pickle(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
